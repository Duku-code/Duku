{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP10+S6NA/+GOK8fKNhrw/h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Duku-code/Duku/blob/main/Text_Mining_NLP_Advanced_AI2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D44vdHn0dMlB",
        "outputId": "cc2c7c58-1264-4f08-8b9d-a0669b722168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.2)\n",
            "Building wheels for collected packages: python-docx\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184491 sha256=218b2434e7c32ec1299ee991a86db697b7882fa09dea3d1e59ced588a89d181d\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
            "Successfully built python-docx\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-0.8.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import docx \n",
        "file_doc = docx.Document('/content/Brexit.docx')"
      ],
      "metadata": {
        "id": "gCbGu5CNamKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(file_doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRV_H02gdXND",
        "outputId": "8603ae16-4a31-499d-a411-f46a519af7fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "docx.document.Document"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "para = file_doc.paragraphs[0]\n",
        "para.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FN3fM3e8dXTk",
        "outputId": "0a0af0ec-2dd2-4705-9a60-491128a7db00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Brexit\\xa0is the impending\\xa0\\xa0of the\\xa0\\xa0(UK) from the\\xa0\\xa0(EU). In a\\xa0, a majority of British voters supported leaving the EU. On 29 March 2017, the\\xa0 invoked\\xa0. The\\xa0\\xa0declares \"exit day\" to be 29 March 2019 at 11\\xa0p.m.\\xa0().'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_paragraphs = []\n",
        "for para in file_doc.paragraphs:\n",
        "  doc_paragraphs.append(para.text)"
      ],
      "metadata": {
        "id": "3pLa88AadXWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_paragraphs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mesdt95FdXe3",
        "outputId": "9501de17-fdc9-4693-cbaf-fb8f82540930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Brexit\\xa0is the impending\\xa0\\xa0of the\\xa0\\xa0(UK) from the\\xa0\\xa0(EU). In a\\xa0, a majority of British voters supported leaving the EU. On 29 March 2017, the\\xa0 invoked\\xa0. The\\xa0\\xa0declares \"exit day\" to be 29 March 2019 at 11\\xa0p.m.\\xa0().',\n",
              " \"Prime Minister\\xa0\\xa0announced the government's intention not to seek permanent membership of the\\xa0\\xa0or the\\xa0\\xa0after leaving the EU and promised to\\xa0\\xa0the\\xa0\\xa0and incorporate existing\\xa0\\xa0into\\xa0.\\xa0A new government department, the\\xa0, was created in July 2016.\",\n",
              " '\\xa0officially started in June 2017, aiming to complete the withdrawal agreement by October 2018. In June 2018, the UK and the EU published a joint progress report outlining agreement on issues including\\xa0,\\xa0\\xa0and\\xa0Euratom.',\n",
              " 'The UK joined the\\xa0\\xa0(EC) in 1973, with membership confirmed by a\\xa0. In the 1970s and 1980s, withdrawal from the EC was advocated mainly by\\xa0Labour Party\\xa0members and\\xa0\\xa0figures. From the 1990s, the main advocates of withdrawal were the newly founded\\xa0\\xa0(UKIP) and an increasing number of Eurosceptic\\xa0\\xa0members. Prime Minister\\xa0\\xa0held the referendum in fulfilment of a 2015 manifesto pledge. Cameron, who had campaigned for \"Remain\", resigned after the referendum result and was succeeded by Theresa May, who called a\\xa0\\xa0less than a year later, in which she lost her overall majority. Her minority government is\\xa0\\xa0by the\\xa0.',\n",
              " 'Six weeks after the referendum, the Bank of England introduced\\xa0\\xa0and lower interest rates, thus allowing both\\xa0\\xa0of\\xa0\\xa0and a rise in inflation that outpaced wage growth for most of 2017. The drop in the value of sterling has been claimed to have been caused in part by hedge-fund managers betting on Brexit against polls predicting a narrow victory for the \"Remain\" camp. ',\n",
              " 'There is a broad consensus in existing economic research that Brexit is likely to reduce the UK\\'s real\\xa0\\xa0in the medium term and long term. There is also agreement among economists that the Brexit referendum itself damaged the economy in the subsequent two years. Studies on effects that have materialised since the referendum show annual losses of £404 for the average UK household, and losses between 1.3% and 2.1% of UK GDP.\\xa0Brexit is likely to reduce immigration from\\xa0\\xa0(EEA) countries to the UK,\\xa0and poses challenges for UK higher education and academic research.\\xa0As of June 2018, the size of the \"\", the UK\\'s inheritance of existing EU trade agreements, and\\xa0\\xa0and other EU member states remain uncertain. The precise impact on the UK depends on whether the process will be a\\xa0.',\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ngrams(doc_paragraphs, n):\n",
        "  words = doc_paragraphs.split()\n",
        "  ngrams = []\n",
        "  for i in range(len(words) - n + 1):\n",
        "    ngram = words[i:i + n]\n",
        "    ngrams.append(ngram)\n",
        "  return ngrams"
      ],
      "metadata": {
        "id": "PXs0XpQTiGGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrams = doc_paragraphs\n",
        "print(ngrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ajn1nyqiGNc",
        "outputId": "74b8a455-fdb8-4df4-a95b-fed1cdbcc494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Brexit\\xa0is the impending\\xa0\\xa0of the\\xa0\\xa0(UK) from the\\xa0\\xa0(EU). In a\\xa0, a majority of British voters supported leaving the EU. On 29 March 2017, the\\xa0 invoked\\xa0. The\\xa0\\xa0declares \"exit day\" to be 29 March 2019 at 11\\xa0p.m.\\xa0().', \"Prime Minister\\xa0\\xa0announced the government's intention not to seek permanent membership of the\\xa0\\xa0or the\\xa0\\xa0after leaving the EU and promised to\\xa0\\xa0the\\xa0\\xa0and incorporate existing\\xa0\\xa0into\\xa0.\\xa0A new government department, the\\xa0, was created in July 2016.\", '\\xa0officially started in June 2017, aiming to complete the withdrawal agreement by October 2018. In June 2018, the UK and the EU published a joint progress report outlining agreement on issues including\\xa0,\\xa0\\xa0and\\xa0Euratom.', 'The UK joined the\\xa0\\xa0(EC) in 1973, with membership confirmed by a\\xa0. In the 1970s and 1980s, withdrawal from the EC was advocated mainly by\\xa0Labour Party\\xa0members and\\xa0\\xa0figures. From the 1990s, the main advocates of withdrawal were the newly founded\\xa0\\xa0(UKIP) and an increasing number of Eurosceptic\\xa0\\xa0members. Prime Minister\\xa0\\xa0held the referendum in fulfilment of a 2015 manifesto pledge. Cameron, who had campaigned for \"Remain\", resigned after the referendum result and was succeeded by Theresa May, who called a\\xa0\\xa0less than a year later, in which she lost her overall majority. Her minority government is\\xa0\\xa0by the\\xa0.', 'Six weeks after the referendum, the Bank of England introduced\\xa0\\xa0and lower interest rates, thus allowing both\\xa0\\xa0of\\xa0\\xa0and a rise in inflation that outpaced wage growth for most of 2017. The drop in the value of sterling has been claimed to have been caused in part by hedge-fund managers betting on Brexit against polls predicting a narrow victory for the \"Remain\" camp. ', 'There is a broad consensus in existing economic research that Brexit is likely to reduce the UK\\'s real\\xa0\\xa0in the medium term and long term. There is also agreement among economists that the Brexit referendum itself damaged the economy in the subsequent two years. Studies on effects that have materialised since the referendum show annual losses of £404 for the average UK household, and losses between 1.3% and 2.1% of UK GDP.\\xa0Brexit is likely to reduce immigration from\\xa0\\xa0(EEA) countries to the UK,\\xa0and poses challenges for UK higher education and academic research.\\xa0As of June 2018, the size of the \"\", the UK\\'s inheritance of existing EU trade agreements, and\\xa0\\xa0and other EU member states remain uncertain. The precise impact on the UK depends on whether the process will be a\\xa0.', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing number of nouns \n",
        "def count_nouns(doc_paragraphs):\n",
        "  import spacy\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  doc = nlp(doc_paragraphs)\n",
        "  nouns = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
        "  return len(nouns)\n"
      ],
      "metadata": {
        "id": "zQksmoe4iGQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = doc_paragraphs\n",
        "\n",
        "number_of_nouns = count_nouns(str(sentence))\n",
        "\n",
        "print(number_of_nouns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-uXthzFiGTK",
        "outputId": "9df7c316-5d2d-4e73-e6ee-f2b9389acd0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#number of pronouns \n",
        "def count_pronouns(doc_paragraphs):\n",
        "  import spacy\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  doc = nlp(doc_paragraphs)\n",
        "  pronouns = [token.text for token in doc if token.pos_ in [\"PRON\", \"PRONOUN\"]]\n",
        "  return len(pronouns)\n"
      ],
      "metadata": {
        "id": "OybqCmReiGdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = doc_paragraphs\n",
        "number_of_pronouns = count_pronouns(str(sentence))\n",
        "print(number_of_pronouns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMdOuiUFqf5s",
        "outputId": "ed26cbd7-dee9-45ce-f4ec-2276b7decf8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_adjectives(doc_paragraphs):\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  doc = nlp(doc_paragraphs)\n",
        "  adjectives = [token.text for token in doc if token.pos_ == \"ADJ\"]\n",
        "  # Return the number of adjectives.\n",
        "  return len(adjectives)\n"
      ],
      "metadata": {
        "id": "dD812oQOqty6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "sentence = doc_paragraphs\n",
        "\n",
        "number_of_adjectives = count_adjectives(str(sentence))\n",
        "\n",
        "print(number_of_adjectives)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPXyrh0PrjVy",
        "outputId": "764e756d-5092-4977-d350-9d19d2a50da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Number of verbs \n",
        "def verbs_count(doc_paragraphs):\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  doc = nlp(doc_paragraphs)\n",
        "  verbs = [token.lemma_ for token in doc if token.pos_ == \"VERB\"]\n",
        "  return len(verbs)\n"
      ],
      "metadata": {
        "id": "fQCbvgl0r2G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = doc_paragraphs\n",
        "number_of_verbs = verbs_count(str(sentence))\n",
        "print(number_of_verbs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvD480B5r2K7",
        "outputId": "cc9a8c0e-a515-4d2f-d7f2-867a41542a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Number of Ad verbs \n",
        "def adverbs_count(doc_paragraphs):\n",
        "  doc = nlp(doc_paragraphs)\n",
        "  adverbs = [token.lemma_ for token in doc if token.pos_ in [\"ADV\", \"ADVERB\"]]\n",
        "  return len(adverbs)\n"
      ],
      "metadata": {
        "id": "mKvcnBOOr2YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = doc_paragraphs\n",
        "number_of_adverbs = verbs_count(str(sentence))\n",
        "print(number_of_adverbs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru4TWrFmr2ff",
        "outputId": "39a59eac-7335-4269-f3cd-b461958c8b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def GeoPoliticalCount(doc_paragraphs):\n",
        "    geopolitical_entities = set()\n",
        "    for line in doc_paragraphs:\n",
        "      for entity in line.split():\n",
        "        if entity.isupper():\n",
        "          geopolitical_entities.add(entity)\n",
        "    return len(geopolitical_entities)\n"
      ],
      "metadata": {
        "id": "jFnYJQ380-Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_geopolitical_entities = GeoPoliticalCount(doc_paragraphs)\n",
        "number_of_geopolitical_entities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwKUE5w20-Pm",
        "outputId": "5efbbe96-acff-4470-9419-d6a0a71566fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def PersonsCount(doc_paragraphs):\n",
        "    persons = set()\n",
        "    for line in doc_paragraphs:\n",
        "      for entity in line.split():\n",
        "        if entity.istitle():\n",
        "          persons.add(entity)\n",
        "\n",
        "    return len(persons)\n",
        "number_of_Person = PersonsCount(doc_paragraphs)\n",
        "number_of_Person\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vbmt3RVv0-TJ",
        "outputId": "120372ba-15a3-48ec-b8fa-5b8711cd5d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def OrganizationsCount(doc_paragraphs):\n",
        "    organizations = set()\n",
        "    for line in doc_paragraphs:\n",
        "      for entity in line.split():\n",
        "        if entity.istitle() and not entity.isupper():\n",
        "          organizations.add(entity)\n",
        "    return len(organizations)\n",
        "Organization = OrganizationsCount(doc_paragraphs)\n",
        "Organization\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q--nJwqH0-ZH",
        "outputId": "715e7db7-19ff-46e7-d013-a5caca2b3427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = doc_paragraphs\n",
        "tokens = nltk.word_tokenize(doc_paragraphs)\n",
        "bigrams = list(nltk.bigrams(tokens))\n",
        "frequencies = nltk.FreqDist(bigrams)\n",
        "most_frequent_bigram = frequencies.most_common(1)[0]\n",
        "print(most_frequent_bigram)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "GYAanoJF0-cG",
        "outputId": "20ef3fe8-4397-481e-be72-4bf482bc60ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-765676b238ee>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_paragraphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_paragraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfrequencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFreqDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmost_frequent_bigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrequencies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "text = doc_paragraphs\n",
        "tokens = nltk.word_tokenize(str(text))\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "tokens = [word for word in tokens if word not in stop_words]\n",
        "nouns = [word for word in tokens if nltk.pos_tag([word])[0][1] == 'NN']\n",
        "most_frequent_noun = max(nouns, key=nouns.count)\n",
        "print(most_frequent_noun)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "yt0JrlVO0-fH",
        "outputId": "6a611a9b-2a35-42ce-a6e5-94c83841275d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-1cafd32c525e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_paragraphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
          ]
        }
      ]
    }
  ]
}